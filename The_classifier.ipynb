{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/cesco/Desktop/Personal/UPY/9/NLP/proyecto/train.csv', header=None, names=['polarity', 'summary', 'reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cesco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             summary  \\\n",
      "0                     Stuning even for the non-gamer   \n",
      "1              The best soundtrack ever to anything.   \n",
      "2                                           Amazing!   \n",
      "3                               Excellent Soundtrack   \n",
      "4  Remember, Pull Your Jaw Off The Floor After He...   \n",
      "\n",
      "                   cleaned_summary  \\\n",
      "0            stuning even nongamer   \n",
      "1    best soundtrack ever anything   \n",
      "2                          amazing   \n",
      "3             excellent soundtrack   \n",
      "4  remember pull jaw floor hearing   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0  This sound track was beautiful! It paints the ...   \n",
      "1  I'm reading a lot of reviews saying that this ...   \n",
      "2  This soundtrack is my favorite music of all ti...   \n",
      "3  I truly like this soundtrack and I enjoy video...   \n",
      "4  If you've played the game, you know how divine...   \n",
      "\n",
      "                                  cleaned_reviewText  \n",
      "0  sound track beautiful paints senery mind well ...  \n",
      "1  im reading lot reviews saying best game soundt...  \n",
      "2  soundtrack favorite music time hands intense s...  \n",
      "3  truly like soundtrack enjoy video game music p...  \n",
      "4  youve played game know divine music every sing...  \n"
     ]
    }
   ],
   "source": [
    "# Descargar las stopwords de NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Cargar los datos (reemplazar con la ruta correcta si es necesario)\n",
    "train_df = pd.read_csv('train.csv', header=None, names=['polarity', 'summary', 'reviewText'])\n",
    "\n",
    "# Reemplazar NaN por cadenas vacías en las columnas de texto\n",
    "train_df['summary'] = train_df['summary'].fillna('')\n",
    "train_df['reviewText'] = train_df['reviewText'].fillna('')\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres no alfabéticos (números, signos de puntuación, etc.)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Eliminar stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Aplicar el preprocesamiento a las columnas de texto\n",
    "train_df['cleaned_summary'] = train_df['summary'].apply(preprocess_text)\n",
    "train_df['cleaned_reviewText'] = train_df['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Verificar cómo quedaron las reseñas\n",
    "print(train_df[['summary', 'cleaned_summary', 'reviewText', 'cleaned_reviewText']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Regresión Logística\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.87    359759\n",
      "           2       0.86      0.87      0.87    360241\n",
      "\n",
      "    accuracy                           0.87    720000\n",
      "   macro avg       0.87      0.87      0.87    720000\n",
      "weighted avg       0.87      0.87      0.87    720000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['cleaned_reviewText'], train_df['polarity'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorizar los textos utilizando TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Crear el clasificador de regresión logística\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir en los datos de prueba\n",
    "y_pred = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Mostrar el reporte de clasificación\n",
    "print(\"Clasificación Regresión Logística\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cesco\\Miniconda3\\envs\\integrador\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m45000/45000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2054s\u001b[0m 46ms/step - accuracy: 0.7584 - loss: 0.4289 - val_accuracy: 0.8912 - val_loss: 0.2603\n",
      "Epoch 2/5\n",
      "\u001b[1m45000/45000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2066s\u001b[0m 46ms/step - accuracy: 0.8893 - loss: 0.2653 - val_accuracy: 0.8968 - val_loss: 0.2482\n",
      "Epoch 3/5\n",
      "\u001b[1m45000/45000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2161s\u001b[0m 48ms/step - accuracy: 0.8941 - loss: 0.2552 - val_accuracy: 0.8991 - val_loss: 0.2432\n",
      "Epoch 4/5\n",
      "\u001b[1m45000/45000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2291s\u001b[0m 51ms/step - accuracy: 0.8962 - loss: 0.2507 - val_accuracy: 0.9002 - val_loss: 0.2411\n",
      "Epoch 5/5\n",
      "\u001b[1m45000/45000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2357s\u001b[0m 52ms/step - accuracy: 0.8973 - loss: 0.2477 - val_accuracy: 0.9012 - val_loss: 0.2398\n",
      "\u001b[1m22500/22500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 12ms/step - accuracy: 0.9011 - loss: 0.2399\n",
      "Accuracy del modelo DNN: 0.9012\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar las etiquetas en números\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Tokenización del texto\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding de las secuencias\n",
    "max_len = 80\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# Crear el modelo DNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train_pad, y_train_encoded, epochs=5, batch_size=64, validation_data=(X_test_pad, y_test_encoded))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test_encoded)\n",
    "print(f\"Accuracy del modelo DNN: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22500/22500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 11ms/step\n",
      "Clasificación DNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90    359759\n",
      "           1       0.90      0.90      0.90    360241\n",
      "\n",
      "    accuracy                           0.90    720000\n",
      "   macro avg       0.90      0.90      0.90    720000\n",
      "weighted avg       0.90      0.90      0.90    720000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Realizar predicciones con el modelo DNN\n",
    "y_pred_dnn = model.predict(X_test_pad)\n",
    "y_pred_dnn = (y_pred_dnn > 0.5).astype(int) \n",
    "# Mostrar el reporte de clasificación\n",
    "print(\"Clasificación DNN\")\n",
    "print(classification_report(y_test_encoded, y_pred_dnn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrador",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
